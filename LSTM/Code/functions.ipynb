{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame , concat\n",
    "import numpy as np\n",
    "from numpy import mean , concatenate\n",
    "from numpy import array , hstack\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure as fig\n",
    "from matplotlib.pylab import rcParams\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import pmdarima as pm\n",
    "\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Activation, Dropout, Bidirectional, TimeDistributed\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files & Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory, pattern = '*', recursive = True):\n",
    "    files = []\n",
    "    for obj in directory.iterdir():\n",
    "        if obj.is_file() & obj.match(pattern):\n",
    "            files.append(obj)\n",
    "        if obj.is_dir() & recursive:\n",
    "            files.extend(get_files(obj, pattern, recursive))\n",
    "    return sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filedata):\n",
    "    li = []\n",
    "    for filename in filedata:\n",
    "        df = pd.read_csv(filename, parse_dates=['timestamp'], dayfirst=True, delimiter=';', decimal=',').groupby([pd.Grouper(freq='1H', key='timestamp')]).kw.mean().reset_index()\n",
    "        li.append(df)\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_c_names(df):\n",
    "    old_cols = list(df.columns.values)\n",
    "    remove = re.compile(r'\\s[\\(\\[].*?[\\)\\]]')\n",
    "    remove2 = re.compile(r'[0-9]*\\.[0-9]+Â°[a-zA-Z]\\s')\n",
    "    wspace = re.compile(r'\\s+')\n",
    "    new_cols = []\n",
    "    for i in old_cols:\n",
    "        i = re.sub(remove, \"\", i)\n",
    "        i = re.sub(remove2, \"\", i)\n",
    "        i = re.sub(wspace, \"_\", i)\n",
    "        new_cols.append(i)\n",
    "    df.columns = new_cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInfo(dataframe):\n",
    "  print(\"Rows     :\", dataframe.shape[0])\n",
    "  print(\"Columns  :\", dataframe.shape[1])\n",
    "  print(\"\\n Features \\n\", dataframe.columns.to_list())\n",
    "  print(\"\\n Missing Values \\n\", dataframe.isnull().any())\n",
    "  print(\"\\n Unique Values \\n\", dataframe.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries, window, cutoff):\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window).mean()\n",
    "    rolstd = timeseries.rolling(window).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20 )\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    pvalue = dftest[1]\n",
    "    if pvalue < cutoff:\n",
    "        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n",
    "    else:\n",
    "        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n",
    "    \n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(y, lags_plots, figsize=(22,8)):\n",
    "    \"Use Series as parameter\"\n",
    "    \n",
    "    # Creating plots of the DF\n",
    "    y = pd.Series(y)\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 3), (1, 0))\n",
    "    ax3 = plt.subplot2grid((3, 3), (1, 1))\n",
    "    ax4 = plt.subplot2grid((3, 3), (2, 0), colspan=2)\n",
    "\n",
    "    y.plot(ax=ax1, figsize=figsize)\n",
    "    ax1.set_title('Power Plant kw-Variation')\n",
    "    plot_acf(y, lags=lags_plots, zero=False, ax=ax2)\n",
    "    plot_pacf(y, lags=lags_plots, zero=False, ax=ax3)\n",
    "    sns.distplot(y, bins=int(sqrt(len(y))), ax=ax4)\n",
    "    ax4.set_title('Distribution Chart')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    adfinput = adfuller(y)\n",
    "    adftest = pd.Series(adfinput[0:4], index=['Test Statistic','p-value','Lags Used','Number of Observations Used'])\n",
    "    adftest = round(adftest,4)\n",
    "    \n",
    "    for key, value in adfinput[4].items():\n",
    "        adftest[\"Critical Value (%s)\"%key] = value.round(4)\n",
    "        \n",
    "    print(adftest)\n",
    "    \n",
    "    if adftest[0].round(2) < adftest[5].round(2):\n",
    "        print('\\nThe Test Statistics is lower than the Critical Value of 5%.\\nThe serie seems to be stationary')\n",
    "    else:\n",
    "        print(\"\\nThe Test Statistics is higher than the Critical Value of 5%.\\nThe serie isn't stationary\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6e34434d82f09c6e83a8a05eef0f5b324bde1d1f8958138553540eeb5796913"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
